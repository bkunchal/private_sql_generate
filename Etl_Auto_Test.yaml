name: ETL Pipeline Testing with PySpark

on:
  push:
    branches:
      - "main"
      - "ci/*"
  pull_request:
    branches:
      - "main"

jobs:
  etl-tests:
    name: Run ETL Tests with PySpark
    runs-on: aexp-ubuntu-latest-medium

    steps:
      # Step 1: Checkout the repository
      - name: Checkout Repo
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      # Step 2: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      # Step 3: Install Python dependencies
      - name: Install Python Dependencies
        run: pip install -r requirements.txt

      # Step 4: Set PYTHONPATH to include the repository root
      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=${PYTHONPATH}:${GITHUB_WORKSPACE}" >> $GITHUB_ENV

      # Step 5: Debug Directory Structure
      - name: Debug Directory Structure
        run: |
          echo "Directory structure:"
          ls -R ${GITHUB_WORKSPACE}
          echo "PYTHONPATH:"
          echo $PYTHONPATH

      # Step 6: Identify Affected Tests
      - name: Identify Affected Tests
        id: identify-affected-tests
        run: python path/to/determine_tests.py

      # Step 7: Run Tests for Affected Tables
      - name: Run Tests for Affected Tables
        if: steps.identify-affected-tests.outcome == 'success'
        run: |
          echo "Running affected tests..."
          while IFS= read -r test_file; do
            echo "Running: $test_file"
            python "$test_file"
          done < affected_tests.txt

      # Post-Job: Clean up temporary files (if necessary)
      - name: Cleanup
        if: always()
        run: |
          rm -f affected_tests.txt
